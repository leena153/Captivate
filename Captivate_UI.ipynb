{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPe1sZvdVQ1sdRM8/Janwv1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leena153/Captivate/blob/main/Captivate_UI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U0pEdbwVSxH3"
      },
      "outputs": [],
      "source": [
        "!pip install gradio youtube-transcript-api transformers openai > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "API_TOKEN=\"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\"\n"
      ],
      "metadata": {
        "id": "BUseBqaeZQA3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import requests\n",
        "from youtube_transcript_api import YouTubeTranscriptApi as YTapi\n",
        "\n",
        "def GetTranscript(video_id):\n",
        "    try:\n",
        "        transcript = YTapi.get_transcript(video_id)\n",
        "        FinalTranscript = ' '.join([i['text'] for i in transcript])\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        FinalTranscript = \"Error retrieving transcript.\"\n",
        "\n",
        "    return FinalTranscript\n",
        "\n",
        "PEGASUS_API_URL = \"https://api-inference.huggingface.co/models/google/pegasus-cnn_dailymail\"\n",
        "FALCON_API_URL = \"https://api-inference.huggingface.co/models/tiiuae/falcon-7b-instruct\"\n",
        "\n",
        "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
        "\n",
        "def query(api_url, payload):\n",
        "    response = requests.post(api_url, headers=headers, json=payload)\n",
        "    return response.json()\n",
        "\n",
        "def videoID(link):\n",
        "    video_id = link.split(\"=\")[1]\n",
        "    return video_id\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    link_box = gr.Textbox(label=\"Enter YouTube Link\")\n",
        "    level = gr.Dropdown(['Beginner', 'Intermediate', 'Expert'], value='Beginner', multiselect=False, label=\"Level\", info=\"Choose the level of summarization you want (only valid for LLM/GPT responses)!\")\n",
        "\n",
        "    submit_btn = gr.Button(\"Summarize!\")\n",
        "\n",
        "    # New textbox to display the transcript\n",
        "    transcript_box = gr.Textbox(label=\"Transcript\", type=\"text\")\n",
        "\n",
        "    with gr.Row(visible=False) as summary_row:\n",
        "        pegasus_out = gr.Textbox(label=\"Output from Finetuned Pegasus\")\n",
        "        falcon_out = gr.Textbox(label=\"Output from Falcon LLM\")\n",
        "\n",
        "    def submit(link, level):\n",
        "        id = videoID(link)\n",
        "        transcript_en = GetTranscript(id)\n",
        "\n",
        "        try:\n",
        "            # Define different prompts based on the specified level for Falcon\n",
        "            prompts = {\n",
        "                'beginner': \"Create a beginner-level summary of the video content.\",\n",
        "                'intermediate': \"Generate an intermediate-level summary of the video content.\",\n",
        "                'expert': \"Craft an expert-level summary of the video content.\"\n",
        "            }\n",
        "\n",
        "            # Select the appropriate prompt based on the specified level\n",
        "            falcon_prompt = prompts.get(level.lower(), \"Invalid level specified.\")\n",
        "\n",
        "            pegasus_output = query(PEGASUS_API_URL, {\"inputs\": transcript_en})\n",
        "            falcon_output = query(FALCON_API_URL, {\"inputs\": f\"{transcript_en[:1024]}\\n\\n{falcon_prompt}\"})\n",
        "\n",
        "            pegasus_summary = pegasus_output[0]['summary_text']\n",
        "            falcon_summary = falcon_output[0]['generated_text'].split('\\n\\n')[-1]\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            pegasus_summary = \"Error summarizing with Pegasus.\"\n",
        "            falcon_summary = \"Error summarizing with Falcon LLM.\"\n",
        "\n",
        "        return {\n",
        "            transcript_box: transcript_en,  # Update transcript box\n",
        "            summary_row: gr.Row(visible=True),\n",
        "            pegasus_out: pegasus_summary,\n",
        "            falcon_out: falcon_summary\n",
        "        }\n",
        "\n",
        "    submit_btn.click(\n",
        "        submit,\n",
        "        [link_box, level],\n",
        "        [transcript_box, pegasus_out, falcon_out, summary_row],  # Include transcript_box\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "SZu9PqQLTDhT",
        "outputId": "4100cb48-4298-4ce9-d002-097375224077"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://37a9fd1cc0ba7c4000.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://37a9fd1cc0ba7c4000.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import openai\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = ''\n",
        "\n",
        "def generate_summary(prompt, level):\n",
        "    # Define different prompts based on the specified level\n",
        "    prompts = {\n",
        "        'beginner': \"Create a summary suitable for beginners based on the provided transcript. Assume the audience has minimal knowledge of the topic. Break down complex ideas into simple explanations, emphasizing key points and fundamental concepts.\",\n",
        "        'intermediate': \"Generate an intermediate-level summary using the transcript. Assume the audience possesses a basic understanding of the topic. Dive into more details, present nuanced information, and maintain a moderate level of complexity in your explanation.\",\n",
        "        'expert': \"Craft an expert-level summary from the transcript. Assume the audience is well-versed in the topic with an in-depth understanding. Provide advanced insights, delve into technical details, and include specialized information relevant to experts in the field.\"\n",
        "    }\n",
        "\n",
        "    # Select the appropriate prompt based on the specified level\n",
        "    selected_prompt = prompts.get(level.lower(), \"Invalid level specified.\")\n",
        "\n",
        "    # Combine the user-provided prompt with the level-specific prompt\n",
        "    combined_prompt = f\"{prompt}\\n\\n{selected_prompt}\"\n",
        "\n",
        "    # Query the OpenAI API\n",
        "    response = openai.chat.completions.create(\n",
        "          model=\"davinci-002\",\n",
        "          messages=[\n",
        "              {\"role\": \"system\", \"content\": combined_prompt},\n",
        "          ],\n",
        "          max_tokens=150\n",
        "    )\n",
        "\n",
        "\n",
        "    # Extract and return the generated summary\n",
        "    summary = response['choices'][0]['message']['content']\n",
        "    return summary\n",
        "\n",
        "# Create a Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=generate_summary,\n",
        "    inputs=[\"text\", \"text\"],  # User prompt and level\n",
        "    outputs=\"text\"  # Generated summary\n",
        ")\n",
        "\n",
        "# Launch the Gradio app\n",
        "iface.launch(debug=True)\n"
      ],
      "metadata": {
        "id": "koaqFi8tvpTH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}